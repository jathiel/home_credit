{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Credit Default Risk\n",
    "\n",
    "Outline:\n",
    "* Load the data\n",
    "* Join tables with Polars - a DataFrame library implemented in Rust language, very fast and memory efficient.  \n",
    "* Create features\n",
    "* Train models\n",
    "* Create a submission table\n",
    "\n",
    "## Load the data\n",
    "Data loading and polars code credit: https://www.kaggle.com/code/jetakow/home-credit-2024-starter-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score \n",
    "\n",
    "dataPath = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_table_dtypes(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    # implement here all desired dtypes for tables\n",
    "    # the following is just an example\n",
    "    for col in df.columns:\n",
    "        # last letter of column name will help you determine the type\n",
    "        if col[-1] in (\"P\", \"A\"):\n",
    "            df = df.with_columns(pl.col(col).cast(pl.Float64).alias(col))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_strings(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for col in df.columns:  \n",
    "        if df[col].dtype.name in ['object', 'string']:\n",
    "            df[col] = df[col].astype(\"string\").astype('category')\n",
    "            current_categories = df[col].cat.categories\n",
    "            new_categories = current_categories.to_list() + [\"Unknown\"]\n",
    "            new_dtype = pd.CategoricalDtype(categories=new_categories, ordered=True)\n",
    "            df[col] = df[col].astype(new_dtype)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data information\n",
    "* basetable:\n",
    "* static:\n",
    "* static_cb:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from  vectorization import *\n",
    "#from data_reduction import *\n",
    "compiled = pd.read_csv(\"W:/Erdos/Project/home_credit/data/csv_files/master_data_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize_dataframe(train_static_cb.to_pandas())\n",
    "# vectorize(train_static_cb.to_pandas())\n",
    "# vectorize_dataframe_for_nn(train_static_cb.to_pandas())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(train_static_cb), type(train_static_cb.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_static.dtypes.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['case_id', 'date_decision', 'MONTH', 'WEEK_NUM', 'target',\n",
       "        'actualdpd_943P', 'actualdpdtolerance_344P', 'addres_district_368M',\n",
       "        'addres_role_871L', 'addres_zip_823M', 'amount_1115A', 'amount_416A',\n",
       "        'amount_4527230A', 'amount_4917619A', 'amtdebitincoming_4809443A',\n",
       "        'amtdebitoutgoing_4809440A', 'amtdepositbalance_4809441A',\n",
       "        'amtdepositincoming_4809444A', 'amtdepositoutgoing_4809442A',\n",
       "        'amtinstpaidbefduel24m_4187115A'],\n",
       "       dtype='object'),\n",
       " array([dtype('int64'), dtype('O'), dtype('bool')], dtype=object))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled.columns[:20], compiled.dtypes.unique()\n",
    "# compiled.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>date_decision</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK_NUM</th>\n",
       "      <th>target</th>\n",
       "      <th>actualdpd_943P</th>\n",
       "      <th>actualdpdtolerance_344P</th>\n",
       "      <th>addres_district_368M</th>\n",
       "      <th>addres_role_871L</th>\n",
       "      <th>addres_zip_823M</th>\n",
       "      <th>...</th>\n",
       "      <th>totaldebtoverduevalue_178A</th>\n",
       "      <th>totaldebtoverduevalue_718A</th>\n",
       "      <th>totaloutstanddebtvalue_39A</th>\n",
       "      <th>totaloutstanddebtvalue_668A</th>\n",
       "      <th>totalsettled_863A</th>\n",
       "      <th>totinstallast1m_4525188A</th>\n",
       "      <th>twobodfilling_608L</th>\n",
       "      <th>type_25L</th>\n",
       "      <th>typesuite_864L</th>\n",
       "      <th>validfrom_1069D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526654</th>\n",
       "      <td>2703450</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>202010</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526655</th>\n",
       "      <td>2703451</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>202010</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526656</th>\n",
       "      <td>2703452</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>202010</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526657</th>\n",
       "      <td>2703453</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>202010</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526658</th>\n",
       "      <td>2703454</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>202010</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1526659 rows Ã— 469 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         case_id date_decision   MONTH  WEEK_NUM  target  actualdpd_943P  \\\n",
       "0              0    2019-01-03  201901         0       0              -1   \n",
       "1              1    2019-01-03  201901         0       0              -1   \n",
       "2              2    2019-01-04  201901         0       0               3   \n",
       "3              3    2019-01-03  201901         0       0               3   \n",
       "4              4    2019-01-04  201901         0       1               3   \n",
       "...          ...           ...     ...       ...     ...             ...   \n",
       "1526654  2703450    2020-10-05  202010        91       0               3   \n",
       "1526655  2703451    2020-10-05  202010        91       0               3   \n",
       "1526656  2703452    2020-10-05  202010        91       0               3   \n",
       "1526657  2703453    2020-10-05  202010        91       0               3   \n",
       "1526658  2703454    2020-10-05  202010        91       0               3   \n",
       "\n",
       "         actualdpdtolerance_344P  addres_district_368M  addres_role_871L  \\\n",
       "0                             -1                    -1                -1   \n",
       "1                             -1                    -1                -1   \n",
       "2                             -1                    -1                -1   \n",
       "3                             -1                    -1                -1   \n",
       "4                             -1                    -1                -1   \n",
       "...                          ...                   ...               ...   \n",
       "1526654                        3                     0                -1   \n",
       "1526655                        3                     0                -1   \n",
       "1526656                        3                     0                -1   \n",
       "1526657                        3                     0                -1   \n",
       "1526658                        3                     0                -1   \n",
       "\n",
       "         addres_zip_823M  ...  totaldebtoverduevalue_178A  \\\n",
       "0                     -1  ...                          -1   \n",
       "1                     -1  ...                          -1   \n",
       "2                     -1  ...                          -1   \n",
       "3                     -1  ...                          -1   \n",
       "4                     -1  ...                          -1   \n",
       "...                  ...  ...                         ...   \n",
       "1526654                0  ...                          -1   \n",
       "1526655                0  ...                          -1   \n",
       "1526656                0  ...                          -1   \n",
       "1526657                0  ...                          -1   \n",
       "1526658                0  ...                          -1   \n",
       "\n",
       "         totaldebtoverduevalue_718A  totaloutstanddebtvalue_39A  \\\n",
       "0                                -1                          -1   \n",
       "1                                -1                          -1   \n",
       "2                                -1                          -1   \n",
       "3                                -1                          -1   \n",
       "4                                -1                          -1   \n",
       "...                             ...                         ...   \n",
       "1526654                          -1                          -1   \n",
       "1526655                          -1                          -1   \n",
       "1526656                          -1                          -1   \n",
       "1526657                          -1                          -1   \n",
       "1526658                          -1                          -1   \n",
       "\n",
       "         totaloutstanddebtvalue_668A  totalsettled_863A  \\\n",
       "0                                 -1                  1   \n",
       "1                                 -1                  1   \n",
       "2                                 -1                  1   \n",
       "3                                 -1                  1   \n",
       "4                                 -1                  1   \n",
       "...                              ...                ...   \n",
       "1526654                           -1                  3   \n",
       "1526655                           -1                  3   \n",
       "1526656                           -1                  1   \n",
       "1526657                           -1                  3   \n",
       "1526658                           -1                  2   \n",
       "\n",
       "         totinstallast1m_4525188A  twobodfilling_608L  type_25L  \\\n",
       "0                              -1                   0         1   \n",
       "1                              -1                   0         1   \n",
       "2                              -1                   0         0   \n",
       "3                              -1                   0         1   \n",
       "4                              -1                   0         1   \n",
       "...                           ...                 ...       ...   \n",
       "1526654                         3                   0         0   \n",
       "1526655                         3                   0         0   \n",
       "1526656                        -1                   1         0   \n",
       "1526657                         1                   1         0   \n",
       "1526658                         0                   0         0   \n",
       "\n",
       "         typesuite_864L  validfrom_1069D  \n",
       "0                    -1               -1  \n",
       "1                    -1               -1  \n",
       "2                     0               -1  \n",
       "3                     0               -1  \n",
       "4                     0               -1  \n",
       "...                 ...              ...  \n",
       "1526654              -1               -1  \n",
       "1526655              -1               -1  \n",
       "1526656              -1               -1  \n",
       "1526657              -1               -1  \n",
       "1526658              -1               -1  \n",
       "\n",
       "[1526659 rows x 469 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize_dataframe(compiled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training..\n",
      "GPU is available. Using the GPU...\n",
      "Train_features: 466\n",
      "Epoch 1/100, Training Loss: 0.1250, Validation Loss: 0.1223 finished in 83.88 seconds\n",
      "Epoch 2/100, Training Loss: 0.1219, Validation Loss: 0.1219 finished in 168.77 seconds\n",
      "Epoch 3/100, Training Loss: 0.1210, Validation Loss: 0.1206 finished in 254.04 seconds\n",
      "Epoch 4/100, Training Loss: 0.1203, Validation Loss: 0.1208 finished in 337.79 seconds\n",
      "Epoch 5/100, Training Loss: 0.1197, Validation Loss: 0.1209 finished in 422.81 seconds\n",
      "Epoch 6/100, Training Loss: 0.1193, Validation Loss: 0.1203 finished in 507.64 seconds\n",
      "Epoch 7/100, Training Loss: 0.1189, Validation Loss: 0.1203 finished in 591.83 seconds\n",
      "Epoch 8/100, Training Loss: 0.1186, Validation Loss: 0.1200 finished in 676.67 seconds\n",
      "Epoch 9/100, Training Loss: 0.1181, Validation Loss: 0.1201 finished in 761.97 seconds\n",
      "Epoch 10/100, Training Loss: 0.1179, Validation Loss: 0.1200 finished in 839.54 seconds\n",
      "Epoch 11/100, Training Loss: 0.1174, Validation Loss: 0.1205 finished in 880.42 seconds\n",
      "Epoch 12/100, Training Loss: 0.1174, Validation Loss: 0.1244 finished in 920.19 seconds\n",
      "Epoch 13/100, Training Loss: 0.1169, Validation Loss: 0.1212 finished in 958.68 seconds\n",
      "Epoch 14/100, Training Loss: 0.1166, Validation Loss: 0.1204 finished in 1002.74 seconds\n",
      "Epoch 15/100, Training Loss: 0.1166, Validation Loss: 0.1216 finished in 1046.01 seconds\n",
      "Epoch 16/100, Training Loss: 0.1161, Validation Loss: 0.1207 finished in 1087.67 seconds\n",
      "Epoch 17/100, Training Loss: 0.1162, Validation Loss: 0.1224 finished in 1133.23 seconds\n",
      "Epoch 18/100, Training Loss: 0.1161, Validation Loss: 0.1234 finished in 1222.72 seconds\n",
      "Epoch 19/100, Training Loss: 0.1165, Validation Loss: 0.1226 finished in 1309.75 seconds\n",
      "Epoch 20/100, Training Loss: 0.1155, Validation Loss: 0.1217 finished in 1387.31 seconds\n",
      "Epoch 21/100, Training Loss: 0.1153, Validation Loss: 0.1234 finished in 1428.99 seconds\n",
      "Epoch 22/100, Training Loss: 0.1153, Validation Loss: 0.1223 finished in 1471.64 seconds\n",
      "Epoch 23/100, Training Loss: 0.1151, Validation Loss: 0.1221 finished in 1516.74 seconds\n",
      "Epoch 24/100, Training Loss: 0.1152, Validation Loss: 0.1219 finished in 1602.78 seconds\n",
      "Epoch 25/100, Training Loss: 0.1148, Validation Loss: 0.1224 finished in 1688.48 seconds\n",
      "Epoch 26/100, Training Loss: 0.1148, Validation Loss: 0.1239 finished in 1771.70 seconds\n",
      "Epoch 27/100, Training Loss: 0.1144, Validation Loss: 0.1230 finished in 1855.92 seconds\n",
      "Epoch 28/100, Training Loss: 0.1143, Validation Loss: 0.1219 finished in 1940.17 seconds\n",
      "Epoch 29/100, Training Loss: 0.1143, Validation Loss: 0.1236 finished in 2023.34 seconds\n",
      "Epoch 30/100, Training Loss: 0.1141, Validation Loss: 0.1238 finished in 2107.30 seconds\n",
      "Epoch 31/100, Training Loss: 0.1143, Validation Loss: 0.1231 finished in 2192.05 seconds\n",
      "Epoch 32/100, Training Loss: 0.1139, Validation Loss: 0.1228 finished in 2250.44 seconds\n",
      "Epoch 33/100, Training Loss: 0.1138, Validation Loss: 0.1239 finished in 2299.91 seconds\n",
      "Epoch 34/100, Training Loss: 0.1137, Validation Loss: 0.1247 finished in 2391.56 seconds\n",
      "Epoch 35/100, Training Loss: 0.1138, Validation Loss: 0.1252 finished in 2560.54 seconds\n",
      "Epoch 36/100, Training Loss: 0.1137, Validation Loss: 0.1240 finished in 2743.64 seconds\n",
      "Epoch 37/100, Training Loss: 0.1134, Validation Loss: 0.1247 finished in 2938.52 seconds\n",
      "Epoch 38/100, Training Loss: 0.1138, Validation Loss: 0.1237 finished in 3143.54 seconds\n",
      "Epoch 39/100, Training Loss: 0.1130, Validation Loss: 0.1245 finished in 3352.06 seconds\n",
      "Epoch 40/100, Training Loss: 0.1134, Validation Loss: 0.1246 finished in 3569.04 seconds\n",
      "Epoch 41/100, Training Loss: 0.1141, Validation Loss: 0.1245 finished in 3785.52 seconds\n",
      "Epoch 42/100, Training Loss: 0.1128, Validation Loss: 0.1254 finished in 3944.18 seconds\n",
      "Epoch 43/100, Training Loss: 0.1131, Validation Loss: 0.1248 finished in 4028.10 seconds\n",
      "Epoch 44/100, Training Loss: 0.1130, Validation Loss: 0.1252 finished in 4092.12 seconds\n",
      "Epoch 45/100, Training Loss: 0.1131, Validation Loss: 0.1251 finished in 4130.36 seconds\n",
      "Epoch 46/100, Training Loss: 0.1131, Validation Loss: 0.1252 finished in 4186.45 seconds\n",
      "Epoch 47/100, Training Loss: 0.1125, Validation Loss: 0.1264 finished in 4270.48 seconds\n",
      "Epoch 48/100, Training Loss: 0.1124, Validation Loss: 0.1254 finished in 4353.98 seconds\n",
      "Epoch 49/100, Training Loss: 0.1122, Validation Loss: 0.1265 finished in 4430.01 seconds\n",
      "Epoch 50/100, Training Loss: 0.1122, Validation Loss: 0.1274 finished in 4506.54 seconds\n",
      "Epoch 51/100, Training Loss: 0.1123, Validation Loss: 0.1260 finished in 4583.41 seconds\n",
      "Epoch 52/100, Training Loss: 0.1134, Validation Loss: 0.1276 finished in 4659.56 seconds\n",
      "Epoch 53/100, Training Loss: 0.1123, Validation Loss: 0.1257 finished in 4738.96 seconds\n",
      "Epoch 54/100, Training Loss: 0.1122, Validation Loss: 0.1266 finished in 4822.28 seconds\n",
      "Epoch 55/100, Training Loss: 0.1132, Validation Loss: 0.1272 finished in 4905.29 seconds\n",
      "Epoch 56/100, Training Loss: 0.1126, Validation Loss: 0.1322 finished in 4988.91 seconds\n",
      "Epoch 57/100, Training Loss: 0.1122, Validation Loss: 0.1278 finished in 5072.89 seconds\n",
      "Epoch 58/100, Training Loss: 0.1123, Validation Loss: 0.1273 finished in 5155.63 seconds\n",
      "Epoch 59/100, Training Loss: 0.1122, Validation Loss: 0.1344 finished in 5239.55 seconds\n",
      "Epoch 60/100, Training Loss: 0.1119, Validation Loss: 0.1264 finished in 5324.21 seconds\n",
      "Epoch 61/100, Training Loss: 0.1116, Validation Loss: 0.1291 finished in 5407.17 seconds\n",
      "Epoch 62/100, Training Loss: 0.1122, Validation Loss: 0.1302 finished in 5491.06 seconds\n",
      "Epoch 63/100, Training Loss: 0.1118, Validation Loss: 0.1288 finished in 5573.54 seconds\n",
      "Epoch 64/100, Training Loss: 0.1125, Validation Loss: 0.1329 finished in 5656.65 seconds\n",
      "Epoch 65/100, Training Loss: 0.1122, Validation Loss: 0.1309 finished in 5741.24 seconds\n",
      "Epoch 66/100, Training Loss: 0.1118, Validation Loss: 0.1308 finished in 5824.59 seconds\n",
      "Epoch 67/100, Training Loss: 0.1119, Validation Loss: 0.1297 finished in 5908.45 seconds\n",
      "Epoch 68/100, Training Loss: 0.1115, Validation Loss: 0.1315 finished in 5992.66 seconds\n",
      "Epoch 69/100, Training Loss: 0.1115, Validation Loss: 0.1327 finished in 6076.20 seconds\n",
      "Epoch 70/100, Training Loss: 0.1118, Validation Loss: 0.1308 finished in 6159.74 seconds\n",
      "Epoch 71/100, Training Loss: 0.1111, Validation Loss: 0.1303 finished in 6244.14 seconds\n",
      "Epoch 72/100, Training Loss: 0.1111, Validation Loss: 0.1316 finished in 6328.12 seconds\n",
      "Epoch 73/100, Training Loss: 0.1115, Validation Loss: 0.1351 finished in 6411.30 seconds\n",
      "Epoch 74/100, Training Loss: 0.1118, Validation Loss: 0.1369 finished in 6494.88 seconds\n",
      "Epoch 75/100, Training Loss: 0.1138, Validation Loss: 0.1390 finished in 6577.23 seconds\n",
      "Epoch 76/100, Training Loss: 0.1140, Validation Loss: 0.1382 finished in 6660.40 seconds\n",
      "Epoch 77/100, Training Loss: 0.1139, Validation Loss: 0.1425 finished in 6744.26 seconds\n",
      "Epoch 78/100, Training Loss: 0.1145, Validation Loss: 0.1322 finished in 6827.11 seconds\n",
      "Epoch 79/100, Training Loss: 0.1140, Validation Loss: 0.1418 finished in 6910.36 seconds\n",
      "Epoch 80/100, Training Loss: 0.1130, Validation Loss: 0.1337 finished in 6995.04 seconds\n",
      "Epoch 81/100, Training Loss: 0.1112, Validation Loss: 0.1322 finished in 7077.28 seconds\n",
      "Epoch 82/100, Training Loss: 0.1108, Validation Loss: 0.1335 finished in 7160.93 seconds\n",
      "Epoch 83/100, Training Loss: 0.1107, Validation Loss: 0.1340 finished in 7244.54 seconds\n",
      "Epoch 84/100, Training Loss: 0.1106, Validation Loss: 0.1326 finished in 7328.09 seconds\n",
      "Epoch 85/100, Training Loss: 0.1117, Validation Loss: 0.1348 finished in 7412.10 seconds\n",
      "Epoch 86/100, Training Loss: 0.1149, Validation Loss: 0.1496 finished in 7496.20 seconds\n",
      "Epoch 87/100, Training Loss: 0.1180, Validation Loss: 0.1330 finished in 7578.70 seconds\n",
      "Epoch 88/100, Training Loss: 0.1105, Validation Loss: 0.1327 finished in 7662.92 seconds\n",
      "Epoch 89/100, Training Loss: 0.1117, Validation Loss: 0.1333 finished in 7745.77 seconds\n",
      "Epoch 90/100, Training Loss: 0.1115, Validation Loss: 0.1361 finished in 7828.66 seconds\n",
      "Epoch 91/100, Training Loss: 0.1118, Validation Loss: 0.1414 finished in 7913.28 seconds\n",
      "Epoch 92/100, Training Loss: 0.1117, Validation Loss: 0.1386 finished in 7996.64 seconds\n",
      "Epoch 93/100, Training Loss: 0.1116, Validation Loss: 0.1465 finished in 8080.03 seconds\n",
      "Epoch 94/100, Training Loss: 0.1115, Validation Loss: 0.1428 finished in 8164.08 seconds\n",
      "Epoch 95/100, Training Loss: 0.1109, Validation Loss: 0.1349 finished in 8247.18 seconds\n",
      "Epoch 96/100, Training Loss: 0.1107, Validation Loss: 0.1407 finished in 8329.77 seconds\n",
      "Epoch 97/100, Training Loss: 0.1117, Validation Loss: 0.1465 finished in 8413.68 seconds\n",
      "Epoch 98/100, Training Loss: 0.1117, Validation Loss: 0.1423 finished in 8497.07 seconds\n",
      "Epoch 99/100, Training Loss: 0.1128, Validation Loss: 0.1435 finished in 8581.63 seconds\n",
      "Epoch 100/100, Training Loss: 0.1144, Validation Loss: 0.1446 finished in 8665.39 seconds\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# labels = np.random.randint(2, size=(num_rows, 1))  # Generates 0 or 1\n",
    "# print(labels.shape)\n",
    "# # Create DataFrame\n",
    "# df = pd.DataFrame(data, columns=['a', 'b', 'c', 'd'])\n",
    "# df['e'] = labels\n",
    "# print(df)\n",
    "\n",
    "X = compiled.loc[:, compiled.columns != \"target\"]\n",
    "y = compiled.loc[:, compiled.columns == \"target\"]\n",
    "# print(X.columns, y.columns)\n",
    "train_loader, test_loader = data_split(X, y)\n",
    "\n",
    "print(\"training..\")\n",
    "train_SimpleNN(train_loader, test_loader)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = compiled.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test=='case_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "home_credit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
